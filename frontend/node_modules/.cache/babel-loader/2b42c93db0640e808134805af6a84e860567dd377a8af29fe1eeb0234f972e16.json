{"ast":null,"code":"export function speak(text, lang = 'en-IN') {\n  try {\n    const synth = window.speechSynthesis;\n    if (!synth) return;\n    const utter = new SpeechSynthesisUtterance(text);\n    utter.lang = lang;\n    synth.cancel();\n    synth.speak(utter);\n  } catch (e) {\n    // no-op\n  }\n}\nexport function listen(onResult, onError) {\n  try {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      onError && onError(new Error('Speech recognition not supported'));\n      return () => {};\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = 'en-IN';\n    recognition.continuous = false;\n    recognition.interimResults = false;\n    recognition.onresult = e => {\n      const transcript = e.results[0][0].transcript;\n      onResult && onResult(transcript);\n    };\n    recognition.onerror = e => onError && onError(e);\n    recognition.start();\n    return () => recognition.stop();\n  } catch (e) {\n    onError && onError(e);\n    return () => {};\n  }\n}","map":{"version":3,"names":["speak","text","lang","synth","window","speechSynthesis","utter","SpeechSynthesisUtterance","cancel","e","listen","onResult","onError","SpeechRecognition","webkitSpeechRecognition","Error","recognition","continuous","interimResults","onresult","transcript","results","onerror","start","stop"],"sources":["C:/Users/Bharg/OneDrive/Desktop/Digital literacy/frontend/src/services/voice.js"],"sourcesContent":["export function speak(text, lang = 'en-IN') {\n  try {\n    const synth = window.speechSynthesis;\n    if (!synth) return;\n    const utter = new SpeechSynthesisUtterance(text);\n    utter.lang = lang;\n    synth.cancel();\n    synth.speak(utter);\n  } catch (e) {\n    // no-op\n  }\n}\n\nexport function listen(onResult, onError) {\n  try {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      onError && onError(new Error('Speech recognition not supported'));\n      return () => {};\n    }\n    const recognition = new SpeechRecognition();\n    recognition.lang = 'en-IN';\n    recognition.continuous = false;\n    recognition.interimResults = false;\n    recognition.onresult = (e) => {\n      const transcript = e.results[0][0].transcript;\n      onResult && onResult(transcript);\n    };\n    recognition.onerror = (e) => onError && onError(e);\n    recognition.start();\n    return () => recognition.stop();\n  } catch (e) {\n    onError && onError(e);\n    return () => {};\n  }\n}"],"mappings":"AAAA,OAAO,SAASA,KAAKA,CAACC,IAAI,EAAEC,IAAI,GAAG,OAAO,EAAE;EAC1C,IAAI;IACF,MAAMC,KAAK,GAAGC,MAAM,CAACC,eAAe;IACpC,IAAI,CAACF,KAAK,EAAE;IACZ,MAAMG,KAAK,GAAG,IAAIC,wBAAwB,CAACN,IAAI,CAAC;IAChDK,KAAK,CAACJ,IAAI,GAAGA,IAAI;IACjBC,KAAK,CAACK,MAAM,CAAC,CAAC;IACdL,KAAK,CAACH,KAAK,CAACM,KAAK,CAAC;EACpB,CAAC,CAAC,OAAOG,CAAC,EAAE;IACV;EAAA;AAEJ;AAEA,OAAO,SAASC,MAAMA,CAACC,QAAQ,EAAEC,OAAO,EAAE;EACxC,IAAI;IACF,MAAMC,iBAAiB,GAAGT,MAAM,CAACS,iBAAiB,IAAIT,MAAM,CAACU,uBAAuB;IACpF,IAAI,CAACD,iBAAiB,EAAE;MACtBD,OAAO,IAAIA,OAAO,CAAC,IAAIG,KAAK,CAAC,kCAAkC,CAAC,CAAC;MACjE,OAAO,MAAM,CAAC,CAAC;IACjB;IACA,MAAMC,WAAW,GAAG,IAAIH,iBAAiB,CAAC,CAAC;IAC3CG,WAAW,CAACd,IAAI,GAAG,OAAO;IAC1Bc,WAAW,CAACC,UAAU,GAAG,KAAK;IAC9BD,WAAW,CAACE,cAAc,GAAG,KAAK;IAClCF,WAAW,CAACG,QAAQ,GAAIV,CAAC,IAAK;MAC5B,MAAMW,UAAU,GAAGX,CAAC,CAACY,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACD,UAAU;MAC7CT,QAAQ,IAAIA,QAAQ,CAACS,UAAU,CAAC;IAClC,CAAC;IACDJ,WAAW,CAACM,OAAO,GAAIb,CAAC,IAAKG,OAAO,IAAIA,OAAO,CAACH,CAAC,CAAC;IAClDO,WAAW,CAACO,KAAK,CAAC,CAAC;IACnB,OAAO,MAAMP,WAAW,CAACQ,IAAI,CAAC,CAAC;EACjC,CAAC,CAAC,OAAOf,CAAC,EAAE;IACVG,OAAO,IAAIA,OAAO,CAACH,CAAC,CAAC;IACrB,OAAO,MAAM,CAAC,CAAC;EACjB;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}